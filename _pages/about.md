---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

[//]: # ({% if site.google_scholar_stats_use_cdn %})

[//]: # ({% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %})

[//]: # ({% else %})

[//]: # ({% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %})

[//]: # ({% endif %})

[//]: # ({% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %})

[//]: # (----------------------------------------------------------------------------------------)

<span class='anchor' id='about-me'></span>

I'm now a Research Fellow in <a href="https://www.ntu.edu.sg/computing">College of Computing and Data Science</a> of <img src="images/NTU.svg" width="15.5" height="20"> <a href="https://www.ntu.edu.sg/">Nanyang Technological University</a>, supervised by Prof. <a href="https://personal.ntu.edu.sg/wslin/Home.html">Weisi Lin</a>. I received my Ph.D. degree at <a href="http://idm.pku.edu.cn/">National Engineering Research Center of Visual Technology</a>, <img src="images/PKU.svg" width="20" height="20"> <a href="https://www.pku.edu.cn/">Peking University</a> in 2023, supervised by Prof. <a href="https://idm.pku.edu.cn/info/1017/1040.htm">Tiejun Huang</a> and Assoc. Prof. <a href="http://www.vie.group/ttj">Tingting Jiang</a>. I received my B.E. degree from <img src="images/TJU.svg" width="20" height="20"> <a href="http://www.tju.edu.cn/">Tianjin University</a> in 2018, supervised by Prof. <a href="http://aiskyeye.com/">Pengfei Zhu</a> and Prof. <a href="http://cic.tju.edu.cn/faculty/jindi/index.htm">Di Jin</a>.

My research interests include Artificial Intelligence, Computer Vision and Deep Learning, especially in the fields of:
- Computer Vision: 
  - Complex Occlusion Scene Understanding, Amodal Segmentation
- AI for Science: 
  - Climate Change Forecasting and Time-Series Analysis

[//]: # (----------------------------------------------------------------------------------------)
<span class='anchor' id='news'></span>

[//]: # (# üî• News)

[//]: # (- *2023.12*: One paper is accepted by <b>AAAI 2024</b>)

[//]: # (- *2023.09*: One paper is accepted by <b>IEEE TMM</b>)

[//]: # (- *2023.07*: One paper is accepted by <b>ICCV 2023</b>)

[//]: # ()

[//]: # (----------------------------------------------------------------------------------------)
<span class='anchor' id='publications'></span>

<head>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>


# üìù Selected Publications 


[//]: # (----------- AURA 2025 Arxiv -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><img src='images/2025_AURA.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Unveiling the Invisible: Reasoning Complex Occlusions Amodally with AURA**

<u><b>Zhixuan Li</b></u>, Hyunse Yoon, Sanghoon Lee, Weisi Lin

<span style="font-size: 90%;"><i>arXiv, 2025</i></span>

<a href="https://arxiv.org/abs/2503.10225">Paper</a> / 
<a href="https://raw.githubusercontent.com/zhixuanli/zhixuanli.github.io/main/bibtex/li2025aura.html">Bibtex</a> /
<a href="https://zhixuanli.github.io/projects/li2025aura/index.html">Project Page</a> 

</div>
</div>

[//]: # (----------- BEAT 2025 Arxiv -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><img src='images/2025_BEAT.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting**

<u><b>Zhixuan Li</b></u>, Naipeng Chen, Seonghwa Choi, Sanghoon Lee, Weisi Lin

<span style="font-size: 90%;"><i>arXiv, 2025</i></span>

<a href="https://arxiv.org/abs/2501.19065">Paper</a> / 
<a href="https://raw.githubusercontent.com/zhixuanli/zhixuanli.github.io/main/bibtex/li2025beat.html">Bibtex</a> /
<a href="https://zhixuanli.github.io/projects/li2025beat/index.html">Project Page</a> 


</div>
</div>


[//]: # (----------- AAAI 2024 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><img src='images/2024_AAAI.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**BLADE: Box-Level Supervised Amodal Segmentation through Directed Expansion**

Zhaochen Liu\*, <u><b>Zhixuan Li*</b></u>, Tingting Jiang (* Equal Contribution)

<span style="font-size: 90%;"><i>AAAI Conference on Artificial Intelligence (**AAAI**), 2024 (EI, CCF A)</i></span>

<a href="https://arxiv.org/abs/2401.01642">Paper</a> / 
<a href="https://raw.githubusercontent.com/zhixuanli/zhixuanli.github.io/main/bibtex/liu2024blade.html">Bibtex</a>

</div>
</div>

[//]: # (----------- TMM 2023 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><img src='images/2023_TMM.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**GIN: Generative INvariant Shape Prior for Amodal Instance Segmentation** 

[//]: # (<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:hqOjcs7Dif8C'></span></strong>)

<u><b>Zhixuan Li</b></u>, Weining Ye, Tingting Jiang, Tiejun Huang

<span style="font-size: 90%;"><i>IEEE Transactions on Multimedia (**TMM**), 2023 (SCI, IF=7.3, JCR Q1, CCF B)</i></span>

<a href="https://ieeexplore.ieee.org/abstract/document/10258334/">Paper</a> / <a href="https://raw.githubusercontent.com/zhixuanli/zhixuanli.github.io/main/bibtex/li2023gin.html">Bibtex</a>

</div>
</div>

[//]: # (----------- ICCV 2023 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><img src='images/2023_ICCV_MUVA.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<p><b>MUVA: A New Large-Scale Benchmark for Multi-view Amodal Instance Segmentation<br></b><b>in the Shopping Scenario</b></p>

<u><b>Zhixuan Li</b></u>, Weining Ye, Juan Terven, Zachary Bennett, Ying Zheng, Tingting Jiang, Tiejun Huang

<span style="font-size: 90%;"><i>International Conference on Computer Vision (**ICCV**), 2023 (EI, CCF A)</i></span>

<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Li_MUVA_A_New_Large-Scale_Benchmark_for_Multi-View_Amodal_Instance_Segmentation_ICCV_2023_paper.pdf">Paper</a> / <a href="https://raw.githubusercontent.com/zhixuanli/zhixuanli.github.io/main/bibtex/li2023muva.html">Bibtex</a> /
<a href="https://zhixuanli.github.io/projects/li2023muva/index.html">Project Page</a> 

</div>
</div>

[//]: # (------------- ICASSP 2023 -----------------)

<div class='paper-box'><div class='paper-box-image'><div><img src='images/2023_ICASSP_OAFormer.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**OAFormer: Learning Occlusion Distinguishable Feature for Amodal Instance Segmentation**

<u><b>Zhixuan Li</b></u>, Ruohua Shi, Tiejun Huang, Tingting Jiang

<span style="font-size: 90%;"><i>IEEE International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2023 (EI, CCF B)</i></span>

<a href="https://ieeexplore.ieee.org/abstract/document/10096534/">Paper</a> /
<a href="https://raw.githubusercontent.com/zhixuanli/zhixuanli.github.io/main/bibtex/li2023oaformer.html">Bibtex</a> /
<a href="https://zhixuanli.github.io/projects/li2023oaformer/index.html">Project Page</a> 


</div>
</div>

[//]: # (------------ ECCV 2022 -------------------)

<div class='paper-box'><div class='paper-box-image'><div><img src='images/2022_ECCV_A3D.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**2D Amodal Instance Segmentation Guided by 3D Shape Prior**

<u><b>Zhixuan Li</b></u>, Weining Ye, Tingting Jiang, Tiejun Huang

<span style="font-size: 90%;"><i>European Conference on Computer Vision (**ECCV**), 2022 (EI, CCF B)</i></span>

<a href="https://link.springer.com/chapter/10.1007/978-3-031-19818-2_10">Paper</a> /
<a href="https://raw.githubusercontent.com/zhixuanli/zhixuanli.github.io/main/bibtex/li2022a3d.html">Bibtex</a>


</div>
</div>


[//]: # (------------ ACCV 2024 -------------------)

<div class='paper-box'><div class='paper-box-image'><div><img src='images/2024_ACCV_VIPNet.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**VIPNet: Combining Viewpoint Information and Shape Priors for Instant Multi-View 3D Reconstruction**


Weining Ye, <u><b>Zhixuan Li</b></u>, Tingting Jiang

<span style="font-size: 90%;"><i>Asian Conference on Computer Vision (**ACCV**), 2024 (EI, CCF C)</i></span>

<a href="https://openaccess.thecvf.com/content/ACCV2024/html/Ye_VIPNet_Combining_Viewpoint_Information_and_Shape_Priors_for_Instant_Multi-View_ACCV_2024_paper.html">Paper</a> /
<a href="https://raw.githubusercontent.com/zhixuanli/zhixuanli.github.io/main/bibtex/ye2024vipnet.html">Bibtex</a>

</div>
</div>

[//]: # (-----------------------------------------------)

<span class='anchor' id='projects'></span>


# üéØ Projects
- Awesome Mixture-of-Experts list: [Github Link](https://github.com/Oliver-FutureAI/Awesome-MoE)
  - This project is a collection of papers and codes about Mixture-of-Experts. We hope to provide a comprehensive and up-to-date resource for researchers and practitioners in this field.


[//]: # (----------------------------------------------------------------------------------------)
<span class='anchor' id='experience'></span>

<style>
  .flag {
    box-shadow: 0 0 1px black;
  }
</style>

# üìñ Experience
- *2024.03 - Present:* Research Fellow, College of Computing and Data Science, <img src="images/NTU.svg" width="15.5" height="20"> Nanyang Technological University, <img src="images/Flag_of_Singapore.svg" width="20" height="20" class="flag"> Singapore.
- *2018.09 - 2023.07:* Doctor of Philosophy, School of Computer Science, <img src="images/PKU.svg" width="20" height="20"> Peking University, Beijing, <img src="images/Flag_of_the_People's_Republic_of_China.svg" width="20" height="20" class="flag"> China.
- *2014.09 - 2018.07:* Bachelor of Engineering, School of Computer Science, <img src="images/TJU.svg" width="20" height="20"> Tianjin University <i>(Outstanding Graduates)</i>, Tianjin, <img src="images/Flag_of_the_People's_Republic_of_China.svg" width="20" height="20" class="flag"> China.

<span class='anchor' id='service'></span>

[//]: # (----------------------------------------------------------------------------------------)
# üíª Service

- Reviewer for 
  - Journals: IEEE TNNLS, IEEE TCSVT, ACM JATS, JVCI, IMAVIS
  - Conferences: CVPR, ICCV, ECCV, AAAI, ICLR, ACM MM, ICASSP, ICPR

[//]: # (----------------------------------------------------------------------------------------)
# -

**Contact:** zhixuan.li at ntu.edu.sg, zhixuanli520 at gmail.com


<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=UA1prgTfM8f4KdsTtZDKPAqAagf4Sr6L0d9xRVyOdrE&co=9fc7e3&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script>
