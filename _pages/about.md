---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

[//]: # ({% if site.google_scholar_stats_use_cdn %})

[//]: # ({% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %})

[//]: # ({% else %})

[//]: # ({% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %})

[//]: # ({% endif %})

[//]: # ({% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %})

[//]: # (----------------------------------------------------------------------------------------)

<span class='anchor' id='about-me'></span>

I'm now a Research Fellow in <a href="https://www.ntu.edu.sg/computing">College of Computing and Data Science</a> of <img src="images/NTU.svg" width="15.5" height="20"> <a href="https://www.ntu.edu.sg/">Nanyang Technological University</a>, supervised by Prof. <a href="https://personal.ntu.edu.sg/wslin/Home.html">Weisi Lin</a>. I received my Ph.D. degree at <a href="http://idm.pku.edu.cn/">National Engineering Research Center of Visual Technology</a>, <img src="images/PKU.svg" width="20" height="20"> <a href="https://www.pku.edu.cn/">Peking University</a> in 2023, supervised by Prof. <a href="https://idm.pku.edu.cn/info/1017/1040.htm">Tiejun Huang</a> and Assoc. Prof. <a href="http://www.vie.group/ttj">Tingting Jiang</a>. I received my B.E. degree from <img src="images/TJU.svg" width="20" height="20"> <a href="http://www.tju.edu.cn/">Tianjin University</a> in 2018, supervised by Prof. <a href="http://aiskyeye.com/">Pengfei Zhu</a> and Prof. <a href="http://cic.tju.edu.cn/faculty/jindi/index.htm">Di Jin</a>.

My research interests include Artificial Intelligence, Computer Vision and Deep Learning, especially in the fields of:
- Computer Vision: 
  - Complex Occlusion Scene Understanding, Amodal Segmentation
- AI for Science: 
  - Climate Change Forecasting and Time-Series Analysis

[//]: # (----------------------------------------------------------------------------------------)
<span class='anchor' id='news'></span>

# üî• News
- *2023.12*: One paper is accepted by <b>AAAI 2024</b>
- *2023.09*: One paper is accepted by <b>IEEE TMM</b>
- *2023.07*: One paper is accepted by <b>ICCV 2023</b>


[//]: # (----------------------------------------------------------------------------------------)
<span class='anchor' id='publications'></span>

# üìù Selected Publications 

The * means equal contribution.

[//]: # (----------- AAAI 2024 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2024</div><img src='images/2024_AAAI.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**BLADE: Box-Level Supervised Amodal Segmentation through Directed Expansion**

Zhaochen Liu\*, <u><b>Zhixuan Li*</b></u>, Tingting Jiang

<span style="font-size: 90%;"><i>AAAI Conference on Artificial Intelligence (AAAI), 2024 (EI, CCF A)</i></span>

<a href="https://arxiv.org/abs/2401.01642">Paper</a> / 
<a href="https://raw.githubusercontent.com/zhixuanli/zhixuanli.github.io/main/bibtex/liu2024blade.html">Bibtex</a>

</div>
</div>

[//]: # (----------- TMM 2023 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TMM 2023</div><img src='images/2023_TMM.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**GIN: Generative INvariant Shape Prior for Amodal Instance Segmentation** 

[//]: # (<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:hqOjcs7Dif8C'></span></strong>)

<u><b>Zhixuan Li</b></u>, Weining Ye, Tingting Jiang, Tiejun Huang

<span style="font-size: 90%;"><i>IEEE Transactions on Multimedia (TMM), 2023 (SCI, IF=7.3, JCR Q1, CCF B)</i></span>

<a href="https://ieeexplore.ieee.org/abstract/document/10258334/">Paper</a> / <a href="https://raw.githubusercontent.com/zhixuanli/zhixuanli.github.io/main/bibtex/li2023gin.html">Bibtex</a>

</div>
</div>

[//]: # (----------- ICCV 2023 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/2023_ICCV_MUVA.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<p><b>MUVA: A New Large-Scale Benchmark for Multi-view Amodal Instance Segmentation<br></b><b>in the Shopping Scenario</b></p>

<u><b>Zhixuan Li</b></u>, Weining Ye, Juan Terven, Zachary Bennett, Ying Zheng, Tingting Jiang, Tiejun Huang

<span style="font-size: 90%;"><i>International Conference on Computer Vision (ICCV), 2023 (EI, CCF A)</i></span>

<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Li_MUVA_A_New_Large-Scale_Benchmark_for_Multi-View_Amodal_Instance_Segmentation_ICCV_2023_paper.pdf">Paper</a> / <a href="https://raw.githubusercontent.com/zhixuanli/zhixuanli.github.io/main/bibtex/li2023muva.html">Bibtex</a> /
<a href="https://zhixuanli.github.io/projects/li2023muva/index.html">Project Page</a> 

</div>
</div>

[//]: # (------------- ICASSP 2023 -----------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICASSP 2023</div><img src='images/2023_ICASSP_OAFormer.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**OAFormer: Learning Occlusion Distinguishable Feature for Amodal Instance Segmentation**

<u><b>Zhixuan Li</b></u>, Ruohua Shi, Tiejun Huang, Tingting Jiang

<span style="font-size: 90%;"><i>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2023 (EI, CCF B)</i></span>

<a href="https://ieeexplore.ieee.org/abstract/document/10096534/">Paper</a> /
<a href="https://raw.githubusercontent.com/zhixuanli/zhixuanli.github.io/main/bibtex/li2023oaformer.html">Bibtex</a>

</div>
</div>

[//]: # (------------ ECCV 2022 -------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2022</div><img src='images/2022_ECCV_A3D.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**2D Amodal Instance Segmentation Guided by 3D Shape Prior**

<u><b>Zhixuan Li</b></u>, Weining Ye, Tingting Jiang, Tiejun Huang

<span style="font-size: 90%;"><i>European Conference on Computer Vision (ECCV), 2022 (EI, CCF B)</i></span>

<a href="https://link.springer.com/chapter/10.1007/978-3-031-19818-2_10">Paper</a> /
<a href="https://raw.githubusercontent.com/zhixuanli/zhixuanli.github.io/main/bibtex/li2022a3d.html">Bibtex</a>


</div>
</div>


[//]: # (------------ ACCV 2024 -------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACCV 2024</div><img src='images/2024_ACCV_VIPNet.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**VIPNet: Combining Viewpoint Information and Shape Priors for Instant Multi-View 3D Reconstruction**


Weining Ye, <u><b>Zhixuan Li</b></u>, Tingting Jiang

<span style="font-size: 90%;"><i>Asian Conference on Computer Vision (ACCV), 2024 (EI, CCF C)</i></span>

<a href="https://openaccess.thecvf.com/content/ACCV2024/html/Ye_VIPNet_Combining_Viewpoint_Information_and_Shape_Priors_for_Instant_Multi-View_ACCV_2024_paper.html">Paper</a> 

</div>
</div>


[//]: # (------------ Frontiers 2022 -------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Frontiers 2022</div><img src='images/2022_Frontiers.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">


<p><b>U-RISC: An Annotated Ultra-High-Resolution Electron Microscopy Dataset Challenging the Existing<br></b><b>Deep Learning Algorithms</b></p>


<p>Ruohua Shi&#42;, Wenyao Wang&#42;, <u><b>Zhixuan Li</b></u>, Liuyuan He, Kaiwen Sheng, Lei Ma, Kai Du,<br>Tingting Jiang, Tiejun Huang</p>


<span style="font-size: 90%;"><i>Frontiers in Computational Neuroscience, 2022 (SCI, IF=3.2, JCR Q2)</i></span>

<a href="https://www.frontiersin.org/journals/computational-neuroscience/articles/10.3389/fncom.2022.842760/full">Paper</a>

</div>
</div>



[//]: # (------------ ICTAI 2017 -------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICTAI 2017</div><img src='images/2017_ICTAI.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Using deep learning for community discovery in social networks**

Di Jin, Meng Ge, <u><b>Zhixuan Li</b></u>, Wenhuan Lu, Dongxiao He, Francoise Fogelman-Soulie

<span style="font-size: 90%;"><i>International Conference on Tools with Artificial Intelligence (ICTAI), 2017 (EI, CCF C)</i></span>

<a href="https://ieeexplore.ieee.org/abstract/document/8371938/">Paper</a> 

</div>
</div>

[//]: # (-----------------------------------------------)

<span class='anchor' id='projects'></span>


# üéØ Projects
- Awesome Mixture-of-Experts list: [Github Link](https://github.com/Oliver-FutureAI/Awesome-MoE)
  - This project is a collection of papers and codes about Mixture-of-Experts. We hope to provide a comprehensive and up-to-date resource for researchers and practitioners in this field.


[//]: # (----------------------------------------------------------------------------------------)
<span class='anchor' id='experience'></span>

# üìñ Experience
- *2024.03 - Present:* Research Fellow, College of Computing and Data Science, <img src="images/NTU.svg" width="15.5" height="20"> Nanyang Technological University, Singapore.
- *2018.09 - 2023.07:* Doctor of Philosophy, School of Computer Science, <img src="images/PKU.svg" width="20" height="20"> Peking University, Beijing, China.
- *2014.09 - 2018.07:* Bachelor of Engineering, School of Computer Science, <img src="images/TJU.svg" width="20" height="20"> Tianjin University <i>(Outstanding Graduates)</i>, Tianjin, &#x1F1E8;&#x1F1F3; China.

<span class='anchor' id='service'></span>

[//]: # (----------------------------------------------------------------------------------------)
# üíª Service

- Reviewer for 
  - Journals: IEEE TNNLS, IEEE TCSVT, ACM JATS, JVCI
  - Conferences: CVPR, ECCV, AAAI, ICLR, ACM MM, ICASSP, ICPR

[//]: # (----------------------------------------------------------------------------------------)
# -

**Contact:** zhixuan.li at ntu.edu.sg, zhixuanli520 at gmail.com

**Last Update:** 31 Jan, 2025

[//]: # (Thanks for the template of <a href="https://github.com/RayeRen/acad-homepage.github.io">Yi Ren</a>)


[//]: # (<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=UA1prgTfM8f4KdsTtZDKPAqAagf4Sr6L0d9xRVyOdrE&cl=ffffff&w=300"></script>)

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=UA1prgTfM8f4KdsTtZDKPAqAagf4Sr6L0d9xRVyOdrE&co=9fc7e3&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script>